# RAG PoC

This project demonstrates a **Retrieval-Augmented Generation (RAG)** pipeline for document-based question answering using an EPUB ebook, **LangChain**, **ChromaDB**, and **Ollama**.

## Features

- Extract text from an EPUB ebook and index it into ChromaDB.
- Use an LLM via Ollama to generate responses based on the indexed text.
- Scalable to multiple books/collections for querying.

## Prerequisites

- Python 3.x
- Install required dependencies from `requirements.txt` using the command below.

```bash
pip install -r requirements.txt
```

## Usage

### 1. Prepare the EPUB File

- Download the EPUB file you want to use.
- Place the file inside the `ebooks/` directory.

### 2. Load the EPUB into the Database

Use the following command to extract the text from the EPUB file and index it into ChromaDB:

```bash
python load_to_db.py
```

This will index the content into a persistent ChromaDB collection, ready for querying.

### 3. Query the Indexed Content via Ollama

After the EPUB content is indexed, use the following command to query the database and get answers generated by the Ollama model:

```bash
python query_ollama.py
```

You can then interact with the model by providing queries, and it will respond based on the indexed EPUB content.

## Additional Scripts

### Delete Collections from ChromaDB

To clear the database or remove specific collections, use:

```bash
python delete_collections_from_db.py
```

This will delete all collections in the ChromaDB database.

## Requirements

- Python 3.x
- Dependencies specified in `requirements.txt`:

  ```
  beautifulsoup4
  chromadb
  ebooklib
  langchain
  langchain-huggingface
  ollama
  pypdf
  sentence-transformers
  transformers
  ```

## Future Enhancements

- Add support for multiple collections (e.g., selecting which collection to query from).
- Implement a web-based UI for easier interaction.
- Load model name and collection configuration from a file.
- Offer the ability to query multiple collections simultaneously.
